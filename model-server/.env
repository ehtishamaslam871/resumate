
OLLAMA_URL=https://lienable-vapidly-savannah.ngrok-free.dev


# Primary model to use (must be pulled in Ollama)
PRIMARY_MODEL=llama3.2:3b

# Fallback model if primary is not available
FALLBACK_MODEL=llama3.2:3b

# Resume parsing mode: "ollama" (AI-powered) or "regex" (fallback)
RESUME_PARSER_MODE=ollama
